task: train

train_interval: [500, 1000000]
eval_interval: [0, 100]

trainer:
    train_domains:
        - mix(subst-eval, comb-like, one-step-add-eq)
        # - load(/mnt/fs5/poesia/peano/learning/sb2/induced-section-0.pkl)
        # - load(/mnt/fs5/poesia/peano/learning/sb2/induced-section-1.pkl)
        # - load(/mnt/fs5/poesia/peano/learning/sb2/induced-section-2.pkl)
        #        - load(/mnt/fs5/poesia/peano/learning//induced-section-0.pkl)
        #        - load(/mnt/fs5/poesia/peano/learning/induced-section-1.pkl)
        #        - load(/mnt/fs5/poesia/peano/learning/induced-section-2.pkl)

    eval_domains:
        - subst-eval
        - comb-like
        - one-step-add-eq

    passing_grade: 0.9
    adjust_search_budget_threshold: 0.05
    search_budget_multiplier: 10

    iterations: 30
    batch_size: 500
    n_searchers: 5
    max_depth: 8
    max_nodes: 5000
    rerank_top_k: 200
    epsilon: 0.1
    algorithm: 'policy-beam-search'

    induce_tactics: true
    induce_loops: true
    n_tactics: 5
    min_tactic_score: 30

    model:
        type: contrastive-policy
        discard_unsolved: true
        train_value_function: false
        solution_augmentation_probability: 0.5
        solution_augmentation_rate: 0.5

        gru:
            embedding_size: 64
            hidden_size: 256
            layers: 2

        gradient_steps: 2048
        batch_size: 1
        lr: 0.0005

        interaction: dot-product
        normalize: true

job:
    wandb_project: peano

hydra:
    job:
        chdir: true
